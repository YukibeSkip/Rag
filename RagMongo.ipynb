{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29968/2364694594.py:26: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/home/bigdata/miniconda3/envs/rag_bida/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 12\n",
      "Documents added to the vector store.\n",
      "Response: [Document(metadata={}, page_content=\"# Plotting SMAs\\nplt.figure(figsize=(12, 6))\\nplt.plot(data['Close'], label='Close Price')\\nplt.plot(data['SMA_20'], label='20-Day SMA')\\nplt.plot(data['SMA_50'], label='50-Day SMA')\\nplt.legend()\\nplt.show()\\nAs you saw in the code we used the following code to calculate the SMA of the last 20 days and then added the results as a column to our data dataframe:ta.sma(data['Close'], length=20)If you want to know which methods are available through pandas_ta on your data, you can use the help function:help(data.ta)Plotting RSIThe Relative Strength Index (RSI) is a momentum oscillator that measures the speed and change of price movements. It oscillates between 0 and 100 and is typically used to identify overbought (above 70) or oversold (below 30) conditions in a market.Here’s how you can calculate and plot RSI using pandas_ta:# we are using the same data as before\\n# Calculate RSI\\ndata['RSI'] = ta.rsi(data['Close'], length=14)\"), Document(metadata={}, page_content=\"# Plotting RSI\\nplt.figure(figsize=(12, 6))\\nplt.plot(data['RSI'], label='RSI')\\nplt.axhline(30, linestyle='--', alpha=0.5, color='red')\\nplt.axhline(70, linestyle='--', alpha=0.5, color='red')\\nplt.title('RSI')\\nplt.legend()\\nplt.show()A Simple Trading StrategyHere is a simple trading strategy using SMA.Buy SignalWhen the short-term SMA crosses above the long-term SMA.Sell SignalWhen the short-term SMA crosses below the long-term SMA.We’ll generate buy and sell signals based on the crossover of a short-term SMA and a long-term SMA, and plot these signals on the chart in green and red.# use the same data as before\\n# Calculate indicators\\ndata['SMA_50'] = ta.sma(data['Close'], length=50)\\ndata['SMA_200'] = ta.sma(data['Close'], length=200)\\n\\n# Generate Buy and Sell signals\\ndata['Buy_Signal'] = np.where((data['SMA_50'] > data['SMA_200']) & (data['SMA_50'].shift(1) <= data['SMA_200'].shift(1)), 1, 0)\\ndata['Sell_Signal'] = np.where((data['SMA_50'] < data['SMA_200']) & (data['SMA_50'].shift(1) >= data['SMA_200'].shift(1)), -1, 0)\\n\\n# Plotting\\nplt.figure(figsize=(14, 8))\"), Document(metadata={}, page_content='plt.show()Summary of strategy:Data Fetching: We use yfinance to download historical data for EUR/USD.Indicator Calculation: We calculate the 50-day and 200-day SMAs using pandas-ta.Signal Generation: Buy signals are generated when the 50-day SMA crosses above the 200-day SMA, and sell signals are generated when the 50-day SMA crosses below the 200-day SMA.Plotting: We plot the closing price and the SMAs as line charts. Buy signals are marked with green triangles, and sell signals are marked with red triangles.As you can see this strategy does not predict the trend well. So you need to consider other ways to generate signals.ConclusionIn this post, I have introduced you to the pandas_ta python library for trading technical analysis to generate technical indicators and buy/sell signals. Algorithmic trading is a very complex field and requires a lot of knowledge regarding not only finance and market analysis, but also programming. You do not want to rely on these simple strategies to risk your money! Trading requires knowledge of risk and emotion management. So, this post was just an introduction to how you can start to learn a useful library and hopefully improve your knowledge of')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.docstore.document import Document\n",
    "from pymongo import MongoClient\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "\n",
    "Mongo_Atlas = \"mongodb+srv://zayrafemi:<db_password>@cluster0.nhoxg.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "\n",
    "client = MongoClient(Mongo_Atlas)\n",
    "\n",
    "DB_NAME = \"vectorstore\"  # Cambia este valor al nombre de tu base de datos\n",
    "COLLECTION_NAME = \"documentos\"  # Cambia este valor al nombre de tu colección\n",
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"docs_python\"\n",
    "\n",
    "# Referencia a la colección de MongoDB\n",
    "MONGODB_COLLECTION = client[DB_NAME][COLLECTION_NAME]\n",
    "\n",
    "# Inicializa los embeddings de HuggingFace\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Configuración de MongoDB Atlas Vector Search\n",
    "vector_store = MongoDBAtlasVectorSearch(\n",
    "    collection=MONGODB_COLLECTION,\n",
    "    embedding=embeddings,\n",
    "    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "    relevance_score_fn=\"cosine\",  \n",
    ")\n",
    "\n",
    "url = \"https://pythonology.eu/using-pandas_ta-to-generate-technical-indicators-and-signals/\"\n",
    "\n",
    "# Obtener el contenido de la página\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "datos = soup.get_text()\n",
    "\n",
    "# Dividir el texto en fragmentos (chunks)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200, chunk_overlap=100, add_start_index=True\n",
    ")\n",
    "\n",
    "# Dividir el texto en fragmentos más pequeños\n",
    "chunks = text_splitter.split_text(datos)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "\n",
    "# Crear embeddings del texto usando HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Crear una lista de documentos a partir de los fragmentos\n",
    "documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Corregir la creación del vectorstore utilizando Chroma y embeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,  # Documentos a agregar\n",
    "    embedding=embedding_model  # Pasamos la instancia del modelo de embeddings\n",
    ")\n",
    "print(\"Documents added to the vector store.\")\n",
    "\n",
    "# Definir el modelo LLM de Ollama\n",
    "llm = OllamaLLM(model=\"llama3.2\", server_url=\"http://localhost:11434\")\n",
    "\n",
    "# Crear el prompt template para el QA\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template=\"Use the context below to answer the user's question:\\n\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    ")\n",
    "\n",
    "# Crear el retriever a partir del vectorstore\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Crear la cadena de QA (RetrievalQA)\n",
    "\n",
    "# Realizar una consulta\n",
    "question = \"what are the oversold and overbought periods?\"\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "response = retriever.invoke(question)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 3120\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "attempt to write a readonly database",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m documents \u001b[38;5;241m=\u001b[39m [Document(page_content\u001b[38;5;241m=\u001b[39mchunk) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Agregar documentos al vectorstore\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43mvectorstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocuments added to the vector store.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Crear el prompt para la pregunta\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_bida/lib/python3.13/site-packages/langchain_core/vectorstores/base.py:287\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[0;34m(self, documents, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    286\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_documents` and `add_texts` has not been implemented \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_bida/lib/python3.13/site-packages/langchain_chroma/vectorstores.py:551\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m         embeddings_without_metadatas \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    548\u001b[0m             [embeddings[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m empty_ids] \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    549\u001b[0m         )\n\u001b[1;32m    550\u001b[0m         ids_without_metadatas \u001b[38;5;241m=\u001b[39m [ids[j] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m empty_ids]\n\u001b[0;32m--> 551\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m            \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_without_metadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    553\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts_without_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids_without_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection\u001b[38;5;241m.\u001b[39mupsert(\n\u001b[1;32m    558\u001b[0m         embeddings\u001b[38;5;241m=\u001b[39membeddings,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    559\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m    560\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    561\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_bida/lib/python3.13/site-packages/chromadb/api/models/Collection.py:343\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update the embeddings, metadatas or documents for provided ids, or create them if they don't exist.\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m upsert_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_prepare_upsert_request(\n\u001b[1;32m    335\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    336\u001b[0m     embeddings\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m     uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[1;32m    341\u001b[0m )\n\u001b[0;32m--> 343\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadatas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdocuments\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupsert_request\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muris\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_bida/lib/python3.13/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_bida/lib/python3.13/site-packages/chromadb/api/segment.py:103\u001b[0m, in \u001b[0;36mrate_limit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rate_limit_enforcer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrate_limit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_bida/lib/python3.13/site-packages/chromadb/rate_limit/simple_rate_limit/__init__.py:23\u001b[0m, in \u001b[0;36mSimpleRateLimitEnforcer.rate_limit.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_bida/lib/python3.13/site-packages/chromadb/api/segment.py:548\u001b[0m, in \u001b[0;36mSegmentAPI._upsert\u001b[0;34m(self, collection_id, ids, embeddings, metadatas, documents, uris, tenant, database)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_embedding_record_set(coll, records_to_submit)\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_quota_enforcer\u001b[38;5;241m.\u001b[39menforce(\n\u001b[1;32m    539\u001b[0m     action\u001b[38;5;241m=\u001b[39mAction\u001b[38;5;241m.\u001b[39mUPSERT,\n\u001b[1;32m    540\u001b[0m     tenant\u001b[38;5;241m=\u001b[39mtenant,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    545\u001b[0m     uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[1;32m    546\u001b[0m )\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_producer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecords_to_submit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_bida/lib/python3.13/site-packages/chromadb/telemetry/opentelemetry/__init__.py:150\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/rag_bida/lib/python3.13/site-packages/chromadb/db/mixins/embeddings_queue.py:243\u001b[0m, in \u001b[0;36mSqlEmbeddingsQueue.submit_embeddings\u001b[0;34m(self, collection_id, embeddings)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# The returning clause does not guarantee order, so we need to do reorder\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# the results. https://www.sqlite.org/lang_returning.html\u001b[39;00m\n\u001b[1;32m    242\u001b[0m sql \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m RETURNING seq_id, id\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Pypika doesn't support RETURNING\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Reorder the results\u001b[39;00m\n\u001b[1;32m    245\u001b[0m seq_ids \u001b[38;5;241m=\u001b[39m [cast(SeqId, \u001b[38;5;28;01mNone\u001b[39;00m)] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m    246\u001b[0m     results\n\u001b[1;32m    247\u001b[0m )  \u001b[38;5;66;03m# Lie to mypy: https://stackoverflow.com/questions/76694215/python-type-casting-when-preallocating-list\u001b[39;00m\n",
      "\u001b[0;31mOperationalError\u001b[0m: attempt to write a readonly database"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.docstore.document import Document\n",
    "from pymongo import MongoClient\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "import PyPDF2\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "Mongo_Atlas = \"mongodb+srv://zayrafemi:<db_password>@cluster0.nhoxg.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "\n",
    "client = MongoClient(Mongo_Atlas)\n",
    "\n",
    "DB_NAME = \"vectorstore\"  # Cambia este valor al nombre de tu base de datos\n",
    "COLLECTION_NAME = \"documentos\"  # Cambia este valor al nombre de tu colección\n",
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"dnd_doc\"\n",
    "\n",
    "# Referencia a la colección de MongoDB\n",
    "MONGODB_COLLECTION = client[DB_NAME][COLLECTION_NAME]\n",
    "\n",
    "# Inicializa los embeddings de HuggingFace\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"jaimevera1107/all-MiniLM-L6-v2-similarity-es\")\n",
    "\n",
    "# Configuración de MongoDB Atlas Vector Search\n",
    "vector_store = MongoDBAtlasVectorSearch(\n",
    "    collection=MONGODB_COLLECTION,\n",
    "    embedding=embeddings,\n",
    "    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "    relevance_score_fn=\"cosine\",  \n",
    ")\n",
    "\n",
    "# Cargar el PDF y extraer el texto\n",
    "pdf_path = \"D&D5Manual.pdf\"\n",
    "\n",
    "with open(pdf_path, \"rb\") as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "# Usar RecursiveCharacterTextSplitter para dividir el texto de manera eficiente\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)  # Definir el tamaño del fragmento y la superposición\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "\n",
    "# Cargar el modelo LLM de Ollama\n",
    "llm = OllamaLLM(model=\"llama3.2\", server_url=\"http://localhost:11434\")\n",
    "\n",
    "# Cargar el modelo de embeddings de HuggingFace\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"jaimevera1107/all-MiniLM-L6-v2-similarity-es\")\n",
    "\n",
    "# Inicializar el vectorstore (almacen de vectores) con Chroma\n",
    "vectorstore = Chroma(persist_directory=\"./vectorstore\", embedding_function=embedding_model)\n",
    "\n",
    "# Crear documentos de Langchain con los fragmentos\n",
    "documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Agregar documentos al vectorstore\n",
    "vectorstore.add_documents(documents)\n",
    "print(\"Documents added to the vector store.\")\n",
    "\n",
    "# Crear el prompt para la pregunta\n",
    "prompt_template = \"\"\"\n",
    "Usa el contexto a continuación para responder la pregunta del usuario:\n",
    "\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Respuesta:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# Crear el retriever a partir del vectorstore\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Hacer una pregunta de ejemplo\n",
    "question = \"¿Cuánto viven los elfos?\"\n",
    "\n",
    "# Obtener la respuesta usando el chain de QA\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "response = retriever.invoke(question)\n",
    "# Imprimir la respuesta\n",
    "print(\"Respuesta:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_bida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
