{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29968/2364694594.py:26: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "/home/bigdata/miniconda3/envs/rag_bida/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 12\n",
      "Documents added to the vector store.\n",
      "Response: [Document(metadata={}, page_content=\"# Plotting SMAs\\nplt.figure(figsize=(12, 6))\\nplt.plot(data['Close'], label='Close Price')\\nplt.plot(data['SMA_20'], label='20-Day SMA')\\nplt.plot(data['SMA_50'], label='50-Day SMA')\\nplt.legend()\\nplt.show()\\nAs you saw in the code we used the following code to calculate the SMA of the last 20 days and then added the results as a column to our data dataframe:ta.sma(data['Close'], length=20)If you want to know which methods are available through pandas_ta on your data, you can use the help function:help(data.ta)Plotting RSIThe Relative Strength Index (RSI) is a momentum oscillator that measures the speed and change of price movements. It oscillates between 0 and 100 and is typically used to identify overbought (above 70) or oversold (below 30) conditions in a market.Here’s how you can calculate and plot RSI using pandas_ta:# we are using the same data as before\\n# Calculate RSI\\ndata['RSI'] = ta.rsi(data['Close'], length=14)\"), Document(metadata={}, page_content=\"# Plotting RSI\\nplt.figure(figsize=(12, 6))\\nplt.plot(data['RSI'], label='RSI')\\nplt.axhline(30, linestyle='--', alpha=0.5, color='red')\\nplt.axhline(70, linestyle='--', alpha=0.5, color='red')\\nplt.title('RSI')\\nplt.legend()\\nplt.show()A Simple Trading StrategyHere is a simple trading strategy using SMA.Buy SignalWhen the short-term SMA crosses above the long-term SMA.Sell SignalWhen the short-term SMA crosses below the long-term SMA.We’ll generate buy and sell signals based on the crossover of a short-term SMA and a long-term SMA, and plot these signals on the chart in green and red.# use the same data as before\\n# Calculate indicators\\ndata['SMA_50'] = ta.sma(data['Close'], length=50)\\ndata['SMA_200'] = ta.sma(data['Close'], length=200)\\n\\n# Generate Buy and Sell signals\\ndata['Buy_Signal'] = np.where((data['SMA_50'] > data['SMA_200']) & (data['SMA_50'].shift(1) <= data['SMA_200'].shift(1)), 1, 0)\\ndata['Sell_Signal'] = np.where((data['SMA_50'] < data['SMA_200']) & (data['SMA_50'].shift(1) >= data['SMA_200'].shift(1)), -1, 0)\\n\\n# Plotting\\nplt.figure(figsize=(14, 8))\"), Document(metadata={}, page_content='plt.show()Summary of strategy:Data Fetching: We use yfinance to download historical data for EUR/USD.Indicator Calculation: We calculate the 50-day and 200-day SMAs using pandas-ta.Signal Generation: Buy signals are generated when the 50-day SMA crosses above the 200-day SMA, and sell signals are generated when the 50-day SMA crosses below the 200-day SMA.Plotting: We plot the closing price and the SMAs as line charts. Buy signals are marked with green triangles, and sell signals are marked with red triangles.As you can see this strategy does not predict the trend well. So you need to consider other ways to generate signals.ConclusionIn this post, I have introduced you to the pandas_ta python library for trading technical analysis to generate technical indicators and buy/sell signals. Algorithmic trading is a very complex field and requires a lot of knowledge regarding not only finance and market analysis, but also programming. You do not want to rely on these simple strategies to risk your money! Trading requires knowledge of risk and emotion management. So, this post was just an introduction to how you can start to learn a useful library and hopefully improve your knowledge of')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.docstore.document import Document\n",
    "from pymongo import MongoClient\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "Mongo_Atlas = \"mongodb+srv://zayrafemi:<db_password>@cluster0.nhoxg.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "\n",
    "client = MongoClient(Mongo_Atlas)\n",
    "\n",
    "DB_NAME = \"vectorstore\"  # Cambia este valor al nombre de tu base de datos\n",
    "COLLECTION_NAME = \"documentos\"  # Cambia este valor al nombre de tu colección\n",
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"docs_python\"\n",
    "\n",
    "# Referencia a la colección de MongoDB\n",
    "MONGODB_COLLECTION = client[DB_NAME][COLLECTION_NAME]\n",
    "\n",
    "# Inicializa los embeddings de HuggingFace\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Configuración de MongoDB Atlas Vector Search\n",
    "vector_store = MongoDBAtlasVectorSearch(\n",
    "    collection=MONGODB_COLLECTION,\n",
    "    embedding=embeddings,\n",
    "    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "    relevance_score_fn=\"cosine\",  \n",
    ")\n",
    "\n",
    "url = \"https://pythonology.eu/using-pandas_ta-to-generate-technical-indicators-and-signals/\"\n",
    "\n",
    "# Obtener el contenido de la página\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "datos = soup.get_text()\n",
    "\n",
    "# Dividir el texto en fragmentos (chunks)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200, chunk_overlap=100, add_start_index=True\n",
    ")\n",
    "\n",
    "# Dividir el texto en fragmentos más pequeños\n",
    "chunks = text_splitter.split_text(datos)\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "\n",
    "# Crear embeddings del texto usando HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Crear una lista de documentos a partir de los fragmentos\n",
    "documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Corregir la creación del vectorstore utilizando Chroma y embeddings\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,  # Documentos a agregar\n",
    "    embedding=embedding_model  # Pasamos la instancia del modelo de embeddings\n",
    ")\n",
    "print(\"Documents added to the vector store.\")\n",
    "\n",
    "# Definir el modelo LLM de Ollama\n",
    "llm = OllamaLLM(model=\"llama3.2\", server_url=\"http://localhost:11434\")\n",
    "\n",
    "# Crear el prompt template para el QA\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    template=\"Use the context below to answer the user's question:\\n\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
    ")\n",
    "\n",
    "# Crear el retriever a partir del vectorstore\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Crear la cadena de QA (RetrievalQA)\n",
    "\n",
    "# Realizar una consulta\n",
    "question = \"what are the oversold and overbought periods?\"\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "response = retriever.invoke(question)\n",
    "print(\"Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63075/418739751.py:27: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"jaimevera1107/all-MiniLM-L6-v2-similarity-es\")\n",
      "/home/bigdata/miniconda3/envs/rag_bida/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     27\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjaimevera1107/all-MiniLM-L6-v2-similarity-es\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Configuración de MongoDB Atlas Vector Search\u001b[39;00m\n\u001b[1;32m     30\u001b[0m vector_store \u001b[38;5;241m=\u001b[39m MongoDBAtlasVectorSearch(\n\u001b[1;32m     31\u001b[0m     collection\u001b[38;5;241m=\u001b[39mMONGODB_COLLECTION,\n\u001b[0;32m---> 32\u001b[0m     embedding\u001b[38;5;241m=\u001b[39m\u001b[43membeddings\u001b[49m,\n\u001b[1;32m     33\u001b[0m     index_name\u001b[38;5;241m=\u001b[39mATLAS_VECTOR_SEARCH_INDEX_NAME,\n\u001b[1;32m     34\u001b[0m     relevance_score_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Cargar el PDF y extraer el texto\u001b[39;00m\n\u001b[1;32m     39\u001b[0m pdf_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD&D5Manual.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain.docstore.document import Document\n",
    "from pymongo import MongoClient\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "import PyPDF2\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "Mongo_Atlas = \"mongodb+srv://zayrafemi:<db_password>@cluster0.nhoxg.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
    "\n",
    "client = MongoClient(Mongo_Atlas)\n",
    "\n",
    "DB_NAME = \"vectorstore\"  # Cambia este valor al nombre de tu base de datos\n",
    "COLLECTION_NAME = \"dnd\"  # Cambia este valor al nombre de tu colección\n",
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"docs_dnd\"\n",
    "\n",
    "# Referencia a la colección de MongoDB\n",
    "MONGODB_COLLECTION = client[DB_NAME][COLLECTION_NAME]\n",
    "\n",
    "# Inicializa los embeddings de HuggingFace\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Configuración de MongoDB Atlas Vector Search\n",
    "vector_store = MongoDBAtlasVectorSearch(\n",
    "    collection=MONGODB_COLLECTION,\n",
    "    embedding=embeddings,\n",
    "    index_name=ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "    relevance_score_fn=\"cosine\",  \n",
    ")\n",
    "\n",
    "\n",
    "# Cargar el PDF y extraer el texto\n",
    "pdf_path = \"D&D5Manual.pdf\"\n",
    "\n",
    "with open(pdf_path, \"rb\") as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "\n",
    "# Usar RecursiveCharacterTextSplitter para dividir el texto de manera eficiente\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)  # Definir el tamaño del fragmento y la superposición\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "\n",
    "# Cargar el modelo LLM de Ollama\n",
    "llm = OllamaLLM(model=\"llama3.2\", server_url=\"http://localhost:11434\")\n",
    "\n",
    "# Cargar el modelo de embeddings de HuggingFace\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"jaimevera1107/all-MiniLM-L6-v2-similarity-es\")\n",
    "\n",
    "# Inicializar el vectorstore (almacen de vectores) con Chroma\n",
    "vectorstore = Chroma(persist_directory=\"./vectorstore\", embedding_function=embedding_model)\n",
    "\n",
    "# Crear documentos de Langchain con los fragmentos\n",
    "documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Agregar documentos al vectorstore\n",
    "vectorstore.add_documents(documents)\n",
    "print(\"Documents added to the vector store.\")\n",
    "\n",
    "# Crear el prompt para la pregunta\n",
    "prompt_template = \"\"\"\n",
    "Usa el contexto a continuación para responder la pregunta del usuario:\n",
    "\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Respuesta:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# Crear el retriever a partir del vectorstore\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Hacer una pregunta de ejemplo\n",
    "question = \"¿Cuánto viven los elfos?\"\n",
    "\n",
    "# Obtener la respuesta usando el chain de QA\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "response = retriever.invoke(question)\n",
    "# Imprimir la respuesta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_bida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
